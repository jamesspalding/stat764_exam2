{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c28e08b5-5242-4769-a4b1-54c2e4c2da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score,mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from pickle import dump,load\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "\n",
    "\n",
    "def cohen_kappa_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return cohen_kappa_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c72964e1-5968-43e9-9e9f-2f31b1630deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Data #####\n",
    "data = pd.read_csv(r'C:\\Users\\annab\\OneDrive\\STAT 764\\Data Sets\\flight_data_full.csv')\n",
    "data = data.drop(['Unnamed: 0','air_time','year', 'month', 'day', 'dest', 'dep_time'],axis=1)\n",
    "\n",
    "\n",
    "#data for first model\n",
    "x = data.drop(['dep_delay', 'delay_severity', 'is_delayed'],axis=1)\n",
    "x = pd.get_dummies(x,dtype=int)\n",
    "y = data['is_delayed']\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x,y,train_size=.7,random_state=764)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9eea42-b1a0-4d4e-b8ef-1b543131b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best parameters: {'ccp_alpha': 0.0, 'max_depth': None, 'min_impurity_decrease': 0.1, 'min_samples_split': 2}\n",
    "\n",
    "##rf = RandomForestClassifier(class_weight='balanced',ccp_alpha=0,max_depth=None,min_impurity_decrease=0.1,min_samples_split=2)\n",
    "\n",
    "##param_grid = {\n",
    "  ##  'n_estimators': [50, 70, 90, 100, 150, 200, 300],\n",
    "   ## 'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "##}\n",
    "\n",
    "##grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=0, scoring=cohen_kappa_scorer)\n",
    "\n",
    "##grid_search.fit(x_train1, y_train1)\n",
    "##best_tree = grid_search.best_estimator_\n",
    "##print(grid_search.best_score_)\n",
    "##y_pred = best_tree.predict(x_test1)\n",
    "##best_params = grid_search.best_params_\n",
    "##print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc55b79-1511-43b0-a237-148d85e5f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best parameters: {'max_features': 'auto', 'n_estimators': 50}, kappa = .457\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced',ccp_alpha=0,max_depth=None,min_samples_split=2,\n",
    "                            max_features='sqrt',n_estimators=200)\n",
    "\n",
    "rf.fit(x_train1, y_train1)\n",
    "y_pred = rf.predict(x_test1)\n",
    "print(classification_report(y_test1, y_pred))\n",
    "\n",
    "y_pred_prob = rf.predict_proba(x_test1)[:, 1]\n",
    "threshold = 0.15 #.79 both\n",
    "y_pred_adjusted = (y_pred_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"Adjusted Threshold Classification Report:\\n\", classification_report(y_test1, y_pred_adjusted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9607eeeb-eba0-44c2-8456-b810047bbe69",
   "metadata": {},
   "source": [
    "Take his y predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711290f1-7884-449b-9e44-3d0cc2e9633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Function to preprocess data\n",
    "def preprocess_data(data):\n",
    "    # Drop unnecessary columns\n",
    "    data = data.drop(columns=['Unnamed: 0', 'air_time', 'year', 'month', 'day', 'dest', 'dep_time'])\n",
    "\n",
    "    # Create target columns\n",
    "    data['is_delayed'] = data['dep_delay'].apply(lambda x: 1 if x >= 30 else 0)  # On-time vs Delayed\n",
    "    data['delay_severity'] = data['dep_delay'].apply(lambda x: 1 if 30 <= x <= 120 else (2 if x > 120 else None))  # Minor/Major\n",
    "\n",
    "    # Drop dep_delay to avoid leakage\n",
    "    data = data.drop(columns=['dep_delay'])\n",
    "\n",
    "    # Fill missing values\n",
    "    data = data.fillna(data.median(numeric_only=True))  # Fill numeric columns with median\n",
    "    categorical_cols = ['carrier', 'origin', 'type', 'manufacturer', 'model', 'engine']\n",
    "    for col in categorical_cols:\n",
    "        data[col] = data[col].fillna(data[col].mode()[0])  # Fill categorical columns with mode\n",
    "\n",
    "    return data\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = pd.read_csv(r'C:\\Users\\annab\\OneDrive\\STAT 764\\Data Sets\\flight_data_full.csv')\n",
    "data = preprocess_data(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57cbd89-ea71-48b8-859f-28b7d4828e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# First Stage: On-time vs Delayed\n",
    "# -----------------------------\n",
    "# Train Random Forest Classifier\n",
    "rf = RandomForestClassifier(\n",
    "    class_weight='balanced', ccp_alpha=0, max_depth=None,\n",
    "    min_samples_split=2, max_features='sqrt', n_estimators=200\n",
    ")\n",
    "rf.fit(x_train1, y_train1)\n",
    "\n",
    "# Predict whether a flight is delayed\n",
    "y_pred = rf.predict(x_test1)\n",
    "print(\"First Stage Classification Report (Default Threshold):\\n\", classification_report(y_test1, y_pred))\n",
    "\n",
    "# Adjust threshold for predicting delays\n",
    "y_pred_prob = rf.predict_proba(x_test1)[:, 1]\n",
    "threshold = 0.15\n",
    "y_pred_adjusted = (y_pred_prob >= threshold).astype(int)\n",
    "print(\"First Stage Classification Report (Adjusted Threshold):\\n\", classification_report(y_test1, y_pred_adjusted))\n",
    "\n",
    "# -----------------------------\n",
    "# Second Stage: Minor vs Major Delays\n",
    "# -----------------------------\n",
    "# Identify delayed flights from the first stage\n",
    "delayed_indices = (y_pred_adjusted == 1)  # Flights predicted as delayed\n",
    "X_test_delayed = x_test1[delayed_indices]  # Features of delayed flights\n",
    "y_test_delayed_actual = data.iloc[X_test_delayed.index]['delay_severity']  # True delay severity\n",
    "\n",
    "# Prepare data for second stage\n",
    "data_delayed = data[data['delay_severity'].notna()]  # Only delayed flights with severity labels\n",
    "X_delayed = data_delayed.drop(columns=['is_delayed', 'delay_severity'])  # Features of delayed flights\n",
    "y_delayed = data_delayed['delay_severity']  # Target: Minor (1) or Major (2)\n",
    "\n",
    "# Train-test split for second stage\n",
    "X_train_delayed, X_test_delayed, y_train_delayed, y_test_delayed = train_test_split(\n",
    "    X_delayed, y_delayed, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Train Decision Tree Classifier for Minor vs Major Delays\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=5, class_weight='balanced')\n",
    "dt_model.fit(X_train_delayed.select_dtypes(include=['number']), y_train_delayed)\n",
    "\n",
    "# Predict and evaluate on second stage\n",
    "y_pred_dt = dt_model.predict(X_test_delayed.select_dtypes(include=['number']))\n",
    "\n",
    "print(\"Second Stage Classification Report (Minor vs Major Delays):\")\n",
    "print(classification_report(y_test_delayed, y_pred_dt, target_names=['Minor Delay', 'Major Delay']))\n",
    "\n",
    "# Plot confusion matrix for second stage\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    dt_model, X_test_delayed.select_dtypes(include=['number']), y_test_delayed,\n",
    "    display_labels=['Minor Delay', 'Major Delay'], cmap=plt.cm.Blues\n",
    ")\n",
    "plt.title(\"Confusion Matrix: Minor vs Major Delays\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
