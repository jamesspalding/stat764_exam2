{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, cohen_kappa_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from pickle import dump,load\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def cohen_kappa_scorer(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return cohen_kappa_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "* Freezing (precipitation + temp < 32)\n",
    "\n",
    "* Weekend (F-M)\n",
    "\n",
    "* Peak times\n",
    "\n",
    "* Tailnum -> seats\n",
    "\n",
    "* Recent (previous) delays by carrier\n",
    "\n",
    "* Recent delays by origin/dest airport\n",
    "\n",
    "* Plane history\n",
    "\n",
    "* 6-9 PM most delays https://www.rd.com/article/avoid-delays-best-time-day-to-fly/\n",
    "\n",
    "* Daily flight count\n",
    "\n",
    "# Process\n",
    "\n",
    "* Categorize as delayed/not, aim to capture as many delays as possible (recall>accuracy), accuracy can be determined in next\n",
    "\n",
    "* Categorize delay severity based on prior categorized delays (regression?)\n",
    "\n",
    "* Find agreement between models\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert numeric response to categorical\n",
    "def categorize_delays(delays):\n",
    "    result = np.where(delays < 30, 'ontime',\n",
    "             np.where((delays >= 30) & (delays <= 120), 'minordelay',\n",
    "             np.where(delays > 120, 'majordelay', delays)))\n",
    "    return result\n",
    "\n",
    "\n",
    "#match columns of original dataset\n",
    "def match_cols(original, new):\n",
    "    original_cols = original.columns\n",
    "\n",
    "    for col in original_cols:\n",
    "        if col not in new.columns:\n",
    "            new[col] = 0\n",
    "\n",
    "    new = new[original_cols]\n",
    "    return new\n",
    "\n",
    "\n",
    "#returns x,y\n",
    "def get_data(path):\n",
    "    flights = pd.read_csv(path)\n",
    "    planes = pd.read_csv('planes.csv')\n",
    "    weather = pd.read_csv('weather.csv')\n",
    "    modeldata = pd.read_csv('flight_data_full.csv') #used for column matching\n",
    "\n",
    "    #impute weather\n",
    "    weather_orig = weather['origin']\n",
    "    weather = weather.drop(['wind_gust','origin','time_hour','year'],axis=1)\n",
    "    imputer = IterativeImputer(sample_posterior=True)\n",
    "    weather = pd.DataFrame(imputer.fit_transform(weather), columns=weather.columns)\n",
    "    weather.insert(0, 'origin', weather_orig)\n",
    "\n",
    "    #impute airplanes\n",
    "    planes = planes.drop('speed',axis=1)\n",
    "    year_by_model = planes.groupby('model')['year'].first()\n",
    "    planes['year'] = planes['year'].fillna(planes['model'].map(year_by_model)) #still some missing... use median\n",
    "    planes['year'] = planes['year'].fillna(planes['year'].median())\n",
    "\n",
    "\n",
    "    ##### New variables #####\n",
    "    #delay severity\n",
    "    flights['delay_severity'] = categorize_delays(flights['dep_delay'])\n",
    "\n",
    "    #existance of a delay\n",
    "    flights['is_delayed'] = np.where(flights['delay_severity'] == 'ontime', 0, 1)\n",
    "\n",
    "    #snowing category\n",
    "    weather['snowing'] = (weather['precip'] > 0) & (weather['temp'] <= 32).astype(int)\n",
    "\n",
    "    #day of week + weekend category (F-M)\n",
    "    flights['date'] = pd.to_datetime(flights[['year', 'month', 'day']])\n",
    "    flights['day_of_week'] = flights['date'].dt.day_name()\n",
    "    flights['is_weekend'] = flights['day_of_week'].isin(['Friday', 'Saturday', 'Sunday', 'Monday']).astype(int)\n",
    "\n",
    "    #peak dates (Thanksgiving (11/28), Christmas, Memorial Day (5/27), July Fourth, and Labor Day(9/2)) pm 5 days\n",
    "    peak_dates = pd.to_datetime(['2013-11-28', '2013-12-25', '2013-07-04', '2013-05-27', '2013-09-02'])\n",
    "\n",
    "    peak_weeks = pd.DataFrame() #get 5 days before/after\n",
    "    for date in peak_dates:\n",
    "        date_range = pd.date_range(start=date - pd.Timedelta(days=5), \n",
    "                                end=date + pd.Timedelta(days=5))\n",
    "        peak_weeks = pd.concat([peak_weeks, pd.DataFrame({'date': date_range})], ignore_index=True)\n",
    "        \n",
    "    flights['peak_week'] = flights['date'].isin(peak_weeks['date']).astype(int)\n",
    "\n",
    "    #peak times (6PM-9PM)\n",
    "    flights['peak_time'] = flights['hour'].between(18, 21)\n",
    "    flights['peak_time'] = flights['peak_time'].astype(int)\n",
    "\n",
    "    #prior airline, origin, and destination delays (takes 2 min to run)\n",
    "    print('Getting new variables (1/3)')\n",
    "    flights['date'] = pd.to_datetime(flights[['year', 'month', 'day', 'hour', 'minute']])\n",
    "\n",
    "    flights['carrier_delay'] = flights.apply(\n",
    "        lambda row: flights[(flights['carrier'] == row['carrier']) & \n",
    "                            (flights['date'] <= row['date']) & \n",
    "                            (flights['date'] > row['date'] - pd.Timedelta(hours=48))]['dep_delay'].mean(), axis=1)\n",
    "\n",
    "    print('Getting new variables (2/3)')\n",
    "    flights['origin_delay'] = flights.apply(\n",
    "        lambda row: flights[(flights['origin'] == row['origin']) & \n",
    "                            (flights['date'] <= row['date']) & \n",
    "                            (flights['date'] > row['date'] - pd.Timedelta(hours=48))]['dep_delay'].mean(), axis=1)\n",
    "\n",
    "    print('Getting new variables (3/3)')\n",
    "    flights['dest_delay'] = flights.apply(\n",
    "        lambda row: flights[(flights['dest'] == row['dest']) & \n",
    "                            (flights['date'] <= row['date']) & \n",
    "                            (flights['date'] > row['date'] - pd.Timedelta(hours=48))]['dep_delay'].mean(), axis=1)\n",
    "\n",
    "    flights['carrier_delay'] = categorize_delays(flights['carrier_delay'])\n",
    "    flights['carrier_delay'] = np.where(flights['carrier_delay'] == 'ontime', 0, 1)\n",
    "\n",
    "    flights['origin_delay'] = categorize_delays(flights['origin_delay'])\n",
    "    flights['origin_delay'] = np.where(flights['origin_delay'] == 'ontime', 0, 1)\n",
    "\n",
    "    flights['dest_delay'] = categorize_delays(flights['dest_delay'])\n",
    "    flights['dest_delay'] = np.where(flights['dest_delay'] == 'ontime', 0, 1)\n",
    "\n",
    "    #number of flights leaving airport same day\n",
    "    flights['flight_volume'] = flights.apply(\n",
    "        lambda row: len(flights[(flights['origin'] == row['origin']) & \n",
    "                            (flights['year'] == row['year']) & \n",
    "                            (flights['month'] == row['month']) & \n",
    "                            (flights['day'] == row['day'])]),axis=1)\n",
    "\n",
    "    #create final dataset\n",
    "    flights = pd.merge(flights, weather, on=['month', 'day', 'hour', 'origin'])\n",
    "\n",
    "    planes['year_manufactured'] = planes['year']\n",
    "    planes = planes.drop('year',axis=1)\n",
    "    flights = pd.merge(flights, planes, on='tailnum')\n",
    "\n",
    "    #responses\n",
    "    ys = flights[['dep_delay', 'delay_severity', 'is_delayed']]\n",
    "\n",
    "    flights = flights.drop(['arr_time', 'arr_delay', 'flight','date','tailnum','air_time',\n",
    "                            'year', 'month', 'day', 'dest', 'dep_time', 'dep_delay', 'delay_severity', 'is_delayed'],axis=1)\n",
    "    \n",
    "    modeldata = modeldata.drop(['Unnamed: 0','air_time','year', 'month', 'day', 'dest', 'dep_time', 'dep_delay', 'delay_severity', 'is_delayed'],axis=1)\n",
    "\n",
    "    #predictors\n",
    "    x = pd.get_dummies(flights,dtype=int)\n",
    "    modeldata = pd.get_dummies(modeldata,dtype=int)\n",
    "\n",
    "    #match columns to original data\n",
    "    x = match_cols(modeldata, x)\n",
    "    \n",
    "    return x,ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting new variables (1/3)\n",
      "Getting new variables (2/3)\n",
      "Getting new variables (3/3)\n"
     ]
    }
   ],
   "source": [
    "##### DON'T RUN THIS #####\n",
    "x,ys = get_data('flights_set0.csv')\n",
    "y = ys['is_delayed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Data #####\n",
    "data = pd.read_csv('flight_data_full.csv')\n",
    "data = data.drop(['Unnamed: 0','air_time','year', 'month', 'day', 'dest', 'dep_time'],axis=1)\n",
    "\n",
    "x = data.drop(['dep_delay', 'delay_severity', 'is_delayed'],axis=1)\n",
    "x = pd.get_dummies(x,dtype=int)\n",
    "y = data['is_delayed']\n",
    "\n",
    "#split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,train_size=.7,random_state=764)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "* Kappa .457\n",
    "\n",
    "* .79 recall on both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'ccp_alpha': 0.0, 'max_depth': None, 'min_impurity_decrease': 0.1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "dc = DecisionTreeClassifier(class_weight='balanced')\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 2, 5, 7, 10],\n",
    "    'min_samples_split': [2, 3, 5, 10, 20],\n",
    "    'min_impurity_decrease': [0.0, 0.01, 0.1],\n",
    "    'ccp_alpha': [0.0, 0.1, 0.2, 0.5, 0.7, 1.0] \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=dc, param_grid=param_grid, cv=5, n_jobs=-1, verbose=0, scoring=cohen_kappa_scorer)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_tree = grid_search.best_estimator_\n",
    "y_pred = best_tree.predict(x_test)\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best parameters: {'ccp_alpha': 0.0, 'max_depth': None, 'min_impurity_decrease': 0.1, 'min_samples_split': 2}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced',ccp_alpha=0,max_depth=None,min_impurity_decrease=0.1,min_samples_split=2)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 70, 90, 100, 150, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=0, scoring=cohen_kappa_scorer)\n",
    "\n",
    "grid_search.fit(x_train, y_train)\n",
    "best_tree = grid_search.best_estimator_\n",
    "print(grid_search.best_score_)\n",
    "y_pred = best_tree.predict(x_test)\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93      5595\n",
      "           1       0.82      0.34      0.49      1083\n",
      "\n",
      "    accuracy                           0.88      6678\n",
      "   macro avg       0.85      0.67      0.71      6678\n",
      "weighted avg       0.88      0.88      0.86      6678\n",
      "\n",
      "Adjusted Threshold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.78      0.86      5595\n",
      "           1       0.41      0.79      0.54      1083\n",
      "\n",
      "    accuracy                           0.78      6678\n",
      "   macro avg       0.68      0.78      0.70      6678\n",
      "weighted avg       0.86      0.78      0.80      6678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Best parameters: {'max_features': 'auto', 'n_estimators': 50}, kappa = .457\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced',ccp_alpha=0,max_depth=None,min_samples_split=2,\n",
    "                            max_features='sqrt',n_estimators=200)\n",
    "\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred_prob = rf.predict_proba(x_test)[:, 1]\n",
    "threshold = 0.15 #.79 both\n",
    "y_pred_adjusted = (y_pred_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"Adjusted Threshold Classification Report:\\n\", classification_report(y_test, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing data function on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting new variables (1/3)\n",
      "Getting new variables (2/3)\n",
      "Getting new variables (3/3)\n"
     ]
    }
   ],
   "source": [
    "x2,y2s = get_data('flights_set1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Threshold Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94     11778\n",
      "           1       0.60      0.95      0.74      2125\n",
      "\n",
      "    accuracy                           0.90     13903\n",
      "   macro avg       0.80      0.92      0.84     13903\n",
      "weighted avg       0.93      0.90      0.91     13903\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test new data\n",
    "y2 = y2s['is_delayed']\n",
    "\n",
    "y_pred = rf.predict(x2)\n",
    "y_pred_prob = rf.predict_proba(x2)[:, 1]\n",
    "threshold = 0.15 \n",
    "y_pred_adjusted = (y_pred_prob >= threshold).astype(int)\n",
    "\n",
    "print(\"Adjusted Threshold Classification Report:\\n\", classification_report(y2, y_pred_adjusted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
